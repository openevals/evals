# OpenEvals

[Join Discord](https://discord.gg/C5uhzejmZk)

OpenEvals is a project to help make evals more legible, reproducible, and less data-contaminated.

If you are looking to make evals without any setup, use the deployed version at [https://openevals.org](https://openevals.org).

## Getting Started

- Set up the frontend by following the instructions in the [client README](client/README.md).
- Set up the backend by following the instructions in the [backend README](backend/README.md).

## Contributing

We welcome your contributions! In particular, we would love help with:

- [ ] Support for more models, especially open-source ones (Integration with Together.ai, etc.)
- [ ] Model-graded validators
- [ ] Additional validators
- [ ] Support for running agents in Docker containers ([METR](https://github.com/METR/task-standard/tree/main) seems like a good framework to implement)
- [ ] General bug fixes

Please [message @belindmo](https://x.com/belindmo) on X/Twitter or [join our Discord](https://discord.gg/C5uhzejmZk) if you have any questions or would like to contribute.

## Team

- Belinda Mo, [@belindmo](https://x.com/belindmo)
- Justin Lin, [@justinlinw](https://x.com/justinlinw)
- Reinier Millo-Sanchez, [@reiniermillo](https://x.com/reiniermillo)
